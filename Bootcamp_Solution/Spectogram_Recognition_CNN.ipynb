{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mustafabozkaya/DeepLearningBootcamp2022/blob/master/Bootcamp_Solution/Spectogram_Recognition_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tQXZ7fatOXo"
      },
      "source": [
        "[<img align=\"Left\" width=\"100\" height=\"100\" src=\"https://thumbs.dreamstime.com/b/mb-initial-letter-vector-logo-icon-mb-initial-letter-vector-logo-icon-204517753.jpg\">](https://github.com/mustafabozkaya)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIOQmr47UV4n"
      },
      "source": [
        "# Spectogram Recognition with CNN\n",
        "\n",
        "---\n",
        "[<img align=\"Left\" width=\"800\" height=\"300\" src=\"https://www.researchgate.net/publication/319081627/figure/fig1/AS:534034566004736@1504335170521/Spectrogram-of-a-speech-signal-with-breath-sound-marked-as-Breath-whose-bounds-are.png\">](#)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsqjPf8Y-YWw"
      },
      "source": [
        "**Colab** için kimlik doğrulama adımları:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAYAYW7fyeqL"
      },
      "source": [
        "**Drive yükleme işlemi**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQBEYuz5-f-b"
      },
      "source": [
        "**Drive da dosya konumlandırmayı yapma işlemleri**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "y-FF6kvPCMO0",
        "outputId": "d9afc100-0aa6-4f47-e1b1-1d75644c0e61"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-df0cfcab423d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/mydrive/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms)\u001b[0m\n\u001b[1;32m    103\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m       \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m       ephemeral=True)\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral)\u001b[0m\n\u001b[1;32m    118\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     _message.blocking_request(\n\u001b[0;32m--> 120\u001b[0;31m         'request_auth', request={'authType': 'dfs_ephemeral'}, timeout_sec=None)\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m   \u001b[0mmountpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    169\u001b[0m   request_id = send_request(\n\u001b[1;32m    170\u001b[0m       request_type, request, parent=parent, expect_reply=True)\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    100\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    101\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/mydrive/',force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4Ow555zoFsU"
      },
      "outputs": [],
      "source": [
        "#unmount drive\n",
        "# drive.flush_and_unmount()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSRCmdYyvd8n"
      },
      "outputs": [],
      "source": [
        "!pwd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_wxcKC60W7E"
      },
      "outputs": [],
      "source": [
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSoiJ6kD1hhd"
      },
      "outputs": [],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lx1-IbDAAHkP"
      },
      "outputs": [],
      "source": [
        "#Copying current content to new editable directory\n",
        "#!cp -r \"../content/drive/MyDrive/spectrograms/\" \"/sample_data/\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmwhitluKIHx"
      },
      "source": [
        "+\n",
        "# Package İnstalling and Controlling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3I0a97d4KHgS"
      },
      "outputs": [],
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MorG7bVkEC-K"
      },
      "outputs": [],
      "source": [
        "!cat /proc/meminfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upGiOWYHLf9t"
      },
      "outputs": [],
      "source": [
        "!pip install -q keras\n",
        "!pip install -q Pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qc_GcnEbCIbu"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zd6kHvnfCgmS"
      },
      "outputs": [],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzIWZIiiKikm"
      },
      "outputs": [],
      "source": [
        "#https://github.com/astrada/google-drive-ocamlfuse/\n",
        "# !mkdir -p drive\n",
        "# !google-drive-ocamlfuse drive\n",
        "# !ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THmIw3mvK5VM"
      },
      "outputs": [],
      "source": [
        "!ls ../content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V45NzAqmLoet"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import load_model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras. layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
        "import glob\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "import cv2 as cv\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"]=(18,8)\n",
        "%matplotlib inline\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0CECC3ML1u5G"
      },
      "outputs": [],
      "source": [
        "cv.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1s7GwkpJORUT"
      },
      "source": [
        "# Configuring İmage datasets folder "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMzna52zK_ED"
      },
      "outputs": [],
      "source": [
        "dataset_dir=f\"/content/mydrive/My Drive/spectrograms/\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqBw9qi-xAHi"
      },
      "outputs": [],
      "source": [
        "for root, dirs, files in os.walk(dataset_dir, topdown=False):\n",
        "    print(root)\n",
        "    print(f\"files type :{type(files)}\")\n",
        "    print(f\"files lenth :{len(files)}\")\n",
        "    #print(os.path.join(root, name))\n",
        "    print(f\"DİR type :{type(dirs)}\")\n",
        "    print(f\"DİR lenth :{len(dirs)}\")\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9lYJtNq3GbZ"
      },
      "outputs": [],
      "source": [
        "for root,dirname, filenames in os.walk(dataset_dir):\n",
        "    for filename in (filenames):\n",
        "        print(os.path.join(root, filename))\n",
        "        break\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtFJlQafLLb4"
      },
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YK9jk6b8f5pZ"
      },
      "source": [
        "# Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vW2Y0qRp1Jny"
      },
      "outputs": [],
      "source": [
        "\n",
        "class_name=\"1\" # set to class name\n",
        "\n",
        "train_files = glob.glob(str(os.path.join(dataset_dir,str(class_name)))+'/*')\n",
        "\n",
        "print(*train_files)\n",
        "print(f\"1 spectogram img lenth :{len(train_files)}\")\n",
        "train_imgs = [img_to_array(load_img(img)) for img in train_files]\n",
        "train_imgs = np.array(train_imgs)\n",
        "train_labels = np.array([fn.split('/')[5].split(\".\")[0].strip() for fn in train_files]) # target , y label\n",
        "\n",
        "print('Train dataset shape:', train_imgs.shape)\n",
        "print('Train labels shape:', train_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tk34RrJk6HSR"
      },
      "outputs": [],
      "source": [
        "train_imgs[100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sW-WtA349rCs"
      },
      "outputs": [],
      "source": [
        "train_labels[100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxvvs7VZ1BCb"
      },
      "outputs": [],
      "source": [
        "# create image datasets "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEdnyOxsK-GH"
      },
      "outputs": [],
      "source": [
        "image_size=(374,500)\n",
        "batch_size=32 # paketler\n",
        "\n",
        "#Setting train/test split\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \n",
        "    directory=dataset_dir,\n",
        "    labels=\"inferred\",\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=42,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    directory=dataset_dir,\n",
        "    labels=\"inferred\",\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=1007,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "#Checking images and labels shapes (amount of images, height, width, color channels)\n",
        "for image_batch, labels_batch in test_ds:\n",
        "  print(image_batch.shape)\n",
        "  print(labels_batch.shape)\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqAPH1xC_Cge"
      },
      "outputs": [],
      "source": [
        "train_ds.class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gowy3cs-IvL"
      },
      "outputs": [],
      "source": [
        "print(type(train_ds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLTHTeqMA0hs"
      },
      "outputs": [],
      "source": [
        "for i in train_ds.take(5):\n",
        "  print(i[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xw2kIT18A0zD"
      },
      "outputs": [],
      "source": [
        "#Checking images and labels shapes (amount of images, height, width, color channels)\n",
        "for image_batch, labels_batch in train_ds:\n",
        "  print(image_batch.shape)\n",
        "  print(labels_batch.shape)\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcCy6z4c-kqL"
      },
      "source": [
        "# Data Visualizaiton"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3kPRAYpB1kO"
      },
      "outputs": [],
      "source": [
        "#Displaying image samples \n",
        "plt.figure(figsize=(18, 18))\n",
        "for images, labels in train_ds.take(1):\n",
        "    for i in range(batch_size):\n",
        "        ax = plt.subplot(4,8,i+1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(int(labels[i]))\n",
        "        plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFsXsg-h6qSM"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQYlWhi36qSN"
      },
      "source": [
        "Before we can build our model and start training, we need to apply one simple augmentation the dataset and that is rescaling. We rescale an input in the (0, 255) range to be in the (0,1) range."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KO6Gob4v6qSN"
      },
      "outputs": [],
      "source": [
        "# Function to prepare our datasets for modelling\n",
        "def prepare(ds, augment=False):\n",
        "    # Define our one transformation\n",
        "    rescale = tf.keras.Sequential(\n",
        "        [tf.keras.layers.experimental.preprocessing.Rescaling(1./255)])\n",
        "    flip_and_rotate = tf.keras.Sequential([\n",
        "        tf.keras.layers.experimental.preprocessing.RandomFlip(\n",
        "            \"horizontal_and_vertical\"),\n",
        "        tf.keras.layers.experimental.preprocessing.RandomRotation(0.2)\n",
        "    ])\n",
        "\n",
        "    # Apply rescale to both datasets and augmentation only to training\n",
        "    ds = ds.map(lambda x, y: (rescale(x, training=True), y))\n",
        "    if augment:\n",
        "        ds = ds.map(lambda x, y: (flip_and_rotate(x, training=True), y))\n",
        "    return ds\n",
        "\n",
        "\n",
        "train_dataset = prepare(train_ds, augment=False)\n",
        "valid_dataset = prepare(test_ds, augment=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQKd5RauPB82"
      },
      "source": [
        "# Modelling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5EdaBRDPGd6"
      },
      "outputs": [],
      "source": [
        "#Checking if the data format i.e the RGB channel is coming first or last so, whatever it may be, model will check first and then input shape will be feeded accordingly.\n",
        "from keras import backend as K\n",
        "if K.image_data_format() == \"channels_first\":\n",
        "    input_shape = (3, img_height, img_width)\n",
        "else:\n",
        "    input_shape = (img_height, img_width, 3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4sDxeRqwwDxI"
      },
      "outputs": [],
      "source": [
        "def conv_net(X_train, y_train): \n",
        "\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    # Create CNN model\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(tf.keras.layers.Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, N_CHANNELS)))\n",
        "    model.add(tf.keras.layers.Conv2D(\n",
        "        32, 3, strides=2, padding='same', activation='relu'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.Dropout(0.5))\n",
        "    model.add(tf.keras.layers.Dense(N_CLASSES, activation='softmax'))\n",
        "\n",
        "  \n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_dl=conv_net()"
      ],
      "metadata": {
        "id": "TQuWz4aG8x-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPwQDtaX6qSO"
      },
      "source": [
        "# Model Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7I3CppJTWrSf"
      },
      "outputs": [],
      "source": [
        "model_dl.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-vFRrUpRsEn"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Compile model\n",
        "model_dl.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=tf.keras.optimizers.RMSprop(),\n",
        "    metrics=['accuracy'],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1g3cwBwXv13"
      },
      "source": [
        "### "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train model for 10 epochs, capture the history\n",
        "history = model_dl.fit(train_dataset,batch_size=batch_size, epochs=10, validation_data=valid_dataset)\n"
      ],
      "metadata": {
        "id": "c2GlvPOg-tHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMEXS-A0Y78X"
      },
      "outputs": [],
      "source": [
        "model_dl.save('save_models/spectogram_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zs1dmePNbNV2"
      },
      "source": [
        "**Rastgele değer için test işlemi**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9DrBMvzcvIF"
      },
      "outputs": [],
      "source": [
        "model_test = model_dl.save('save_models/spectogram_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3qUBCIbgoWn"
      },
      "source": [
        "# Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60chUuK_gq3y"
      },
      "outputs": [],
      "source": [
        "# Plot the loss curves for training and validation.\n",
        "history_dict = history.history\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "epochs = range(1, len(loss_values)+1)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CsFA0XN6qSP"
      },
      "outputs": [],
      "source": [
        "# Plot the accuracy curves for training and validation.\n",
        "acc_values = history_dict['accuracy']\n",
        "val_acc_values = history_dict['val_accuracy']\n",
        "epochs = range(1, len(acc_values)+1)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(epochs, acc_values, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc_values, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cux1Lscj6qSP"
      },
      "source": [
        "We can compute the final loss and accuracy score on our valid dataset using the evaluate() function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrfxWRdq6qSP"
      },
      "outputs": [],
      "source": [
        "# Compute the final loss and accuracy\n",
        "final_loss, final_acc = model.evaluate(valid_dataset, verbose=0)\n",
        "print(\"Final loss: {0:.6f}, final accuracy: {1:.6f}\".format(\n",
        "    final_loss, final_acc))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4YmI6526qSP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}